library(stringr)
library(gbm)
library(glmnetUtils) # boosting
library(randomForest)
# install.packages("scales")              # dependency of plot_glmnet
source("functions/plot_glmnet.R")
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
set.seed(471) # set seed for reproducibility
ridge_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = 0,                 # alpha = 0 for ridge
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
set.seed(471) # set seed before cross-validation for reproducibility
lasso_fit = cv.glmnet(theftrate ~. -state -county -fips , alpha = 1, nfolds = 10, data = theft_train)
plot(lasso_fit)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
num_features = lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se]
sprintf("The number of features (excluding intercept) selected (1se): %i",
num_features)
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(coefficient))
plot_glmnet(lasso_fit, theft_train)
View(theft_train)
plot(gbm_3, i.var = "saversperhouses", n.trees =
optimal_num_trees)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
library(gbm)
library(glmnetUtils) # boosting
library(randomForest)
# install.packages("scales")              # dependency of plot_glmnet
source("functions/plot_glmnet.R")
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
set.seed(471) # set seed for reproducibility
ridge_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = 0,                 # alpha = 0 for ridge
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
set.seed(471) # set seed before cross-validation for reproducibility
lasso_fit = cv.glmnet(theftrate ~. -state -county -fips , alpha = 1, nfolds = 10, data = theft_train)
plot(lasso_fit)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
num_features = lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se]
sprintf("The number of features (excluding intercept) selected (1se): %i",
num_features)
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(coefficient))
plot_glmnet(lasso_fit, theft_train)
elnet_fit = cva.glmnet(theftrate ~ . -fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
elnet_fit_best = extract_best_elnet(elnet_fit)
elnet_fit_best$alpha
plot(elnet_fit_best)
plot_glmnet(elnet_fit_best, theft_train)
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
extract_std_coefs(elnet_fit_best, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(abs(coefficient)))
set.seed(471) # set seed for reproducibility
final_elnet_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = elnet_fit_best$alpha,
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
set.seed(471) # set seed for reproducibility
mvalues = seq(4,16, by = 1)
oob_errors = numeric(length(mvalues))
ntree = 500
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit = randomForest(theftrate ~. -fips -state - county, mtry = m, data = theft_train)
oob_errors[idx] = rf_fit$mse[ntree]
}
tibble(m = mvalues, oob_err = oob_errors) %>%
ggplot(aes(x = m, y = oob_err)) +
geom_line() + geom_point() +
scale_x_continuous(breaks = mvalues) +
theme_bw()
set.seed(471) # set seed for reproducibility
rf_11 = randomForest(theftrate ~ .-fips -state -county, mtry = 11, data = theft_train)
rf_11$importance
varImpPlot(rf_11,n.var = 10)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 3
gbm_3 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
ntrees = 1000
cv_errors = bind_rows(
tibble(ntree = 1:ntrees, cv_err = gbm_1$cv.error, Depth = 1),
tibble(ntree = 1:ntrees, cv_err = gbm_2$cv.error, Depth = 2),
tibble(ntree = 1:ntrees, cv_err = gbm_3$cv.error, Depth = 3)
) %>% mutate(Depth = factor(Depth))
# plot CV errors
mins = cv_errors %>% group_by(Depth) %>% summarise(min_err = min(cv_err))
gbm.perf(gbm_3, plot.it = FALSE)
cv_errors %>%
ggplot(aes(x = ntree, y = cv_err, colour = Depth)) +
geom_line() + theme_bw() +
geom_hline(aes(yintercept = min_err, color = Depth),
data = mins, linetype = "dashed") +
labs(y = "CV Error", x = "Trees") + scale_y_log10()
gbm_fit_optimal = gbm_3
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_3, i.var = "housing_density",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "poor_fair_health",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "pertrump", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "PctEmpFIRE", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "saversperhouses", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "pop_density", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "unemp_bens_possible", n.trees =
optimal_num_trees)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_11, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Error")
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
"Elastic Net" = elnet_RMSE, "Random Forest" = rf_RMSE, Boosting = gbm_RMSE, Response_Mean) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test Error")
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE, Response_Mean) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test Error")
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE, Response_Mean = mean(theft_test$theftrate)) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test Error")
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test Error")
Response_Mean = mean(theft_test$theftrate)
Response_Mean = mean(theft_test$theftrate)
Response_Mean
set.seed(471) # set seed for reproducibility
rf_13 = randomForest(theftrate ~ .-fips -state -county, mtry = 13, data = theft_train)
rf_13$importance
varImpPlot(rf_11,n.var = 10)
varImpPlot(rf_13,n.var = 10)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
elnet_fit = cva.glmnet(theftrate ~ . -fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
library(gbm)
library(glmnetUtils) # boosting
library(randomForest)
# install.packages("scales")              # dependency of plot_glmnet
source("functions/plot_glmnet.R")
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
set.seed(471) # set seed for reproducibility
ridge_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = 0,                 # alpha = 0 for ridge
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
set.seed(471) # set seed before cross-validation for reproducibility
lasso_fit = cv.glmnet(theftrate ~. -state -county -fips , alpha = 1, nfolds = 10, data = theft_train)
plot(lasso_fit)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
num_features = lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se]
sprintf("The number of features (excluding intercept) selected (1se): %i",
num_features)
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(coefficient))
plot_glmnet(lasso_fit, theft_train)
elnet_fit = cva.glmnet(theftrate ~ . -fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
elnet_fit = cva.glmnet(theftrate ~ .-fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
elnet_fit_best = extract_best_elnet(elnet_fit)
elnet_fit_best$alpha
plot(elnet_fit_best)
plot_glmnet(elnet_fit_best, theft_train)
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
extract_std_coefs(elnet_fit_best, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(abs(coefficient)))
set.seed(471) # set seed for reproducibility
final_elnet_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = elnet_fit_best$alpha,
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
set.seed(471) # set seed before cross-validation for reproducibility
lasso_fit = cv.glmnet(theftrate ~. -state -county -fips , alpha = 1, nfolds = 10, data = theft_train)
plot(lasso_fit)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
num_features = lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se]
sprintf("The number of features (excluding intercept) selected (1se): %i",
num_features)
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(coefficient))
plot_glmnet(lasso_fit, theft_train)
elnet_fit = cva.glmnet(theftrate ~ .-fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
elnet_fit$alpha
elnet_fit$alpha
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
elnet_fit_best = extract_best_elnet(elnet_fit)
elnet_fit_best$alpha
plot(elnet_fit_best)
plot_glmnet(elnet_fit_best, theft_train)
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
extract_std_coefs(elnet_fit_best, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(abs(coefficient)))
set.seed(471) # set seed for reproducibility
final_elnet_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = elnet_fit_best$alpha,
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
set.seed(471) # set seed for reproducibility
final_elnet_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = elnet_fit_best$alpha,
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
set.seed(471) # set seed for reproducibility
mvalues = seq(4,16, by = 1)
oob_errors = numeric(length(mvalues))
ntree = 500
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit = randomForest(theftrate ~. -fips -state - county, mtry = m, data = theft_train)
oob_errors[idx] = rf_fit$mse[ntree]
}
OLS_Predictions = predict((lm(theftrate ~ . -state, county, fips, data = theft_train), newdata = theft_test))
OLS_Predictions = predict((lm(theftrate ~ . -state, -county -fips, data = theft_train), newdata = theft_test))
OLS_Predictions = predict((lm(theftrate ~ . -state -county -fips, data = theft_train), newdata = theft_test))
OLS_Predictions = predict((lm(theftrate ~ . -state -county -fips, data = theft_train)), newdata = theft_test)
theft_train = read_csv("../data/clean/theft_train.csv") %>% select(-fips, -county, -state)
theft_test = read_csv("../data/clean/theft_test.csv") %>% select(-fips, -county, -state)
# OLS
OLS_Predictions = predict((lm(theftrate ~ .-state -county -fips, data = theft_train)), newdata = theft_test)
lm(theftrate ~ .-state -county -fips, data = theft_train)
# OLS
OLS_Predictions = predict((lm(theftrate ~ ., data = theft_train)), newdata = theft_test)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
OLS_Predictions = predict((lm(theftrate ~ ., data = theft_train)), newdata = theft_test)
OLS_RMSE = sqrt(mean((OLS_predictions-theft_test$theftrate)^2))
# OLS
testforOLS = theft_test %>% select(-fips, -county, -state)
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
# OLS
testforOLS = theft_test %>% select(-fips, -county, -state)
OLS_Predictions = predict((lm(theftrate ~ ., data = theft_train)), newdata = testforOLS)
# OLS
testforOLS = theft_test %>% select(-fips, -county, -state)
OLS_Predictions = predict((lm(theftrate ~ . -county -state -fips, data = theft_train)), newdata = testforOLS)
# OLS
testforOLS = theft_test %>% select(-fips, -county, -state)
OLS_Predictions = predict((lm(theftrate ~ . -county -state -fips, data = theft_train)), newdata = theft_test)
# OLS
testforOLS = theft_test %>% select(-fips)
OLS_Predictions = predict((lm(theftrate ~ . -county -state -fips, data = theft_train)), newdata = testforOLS)
# OLS
testforOLS = theft_test %>% select(-fips)
lm_fit = lm(theftrate ~ . -county -state -fips, data = theft_train)
OLS_Predictions = predict(lm_fit, newdata = testforOLS)
# OLS
testforOLS = theft_test %>% select(-fips)
lm_fit = lm(theftrate ~ . -county -state -fips, data = theft_train)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
# OLS
testforOLS = theft_test %>% select(-fips,  -county, -state)
lm_fit = lm(theftrate ~ . -county -state -fips, data = theft_train)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
# OLS
testforOLS = theft_test %>% select(-fips,  -county, -state)
lm_fit = lm(theftrate ~ . -county -state -fips, data = testforOLS)
# OLS
testforOLS = theft_test %>% select(-county, -state)
trainforOLS = theft_train %>% select(-county, -state)
lm_fit = lm(theftrate ~ ., data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
OLS_RMSE = sqrt(mean((OLS_predictions-testforOLS$theftrate)^2))
# OLS
testforOLS = theft_test %>% select(-fips)
trainforOLS = theft_train %>% select(-fips)
lm_fit = lm(theftrate ~ .-county -state, data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
OLS_RMSE = sqrt(mean((OLS_predictions-testforOLS$theftrate)^2))
# OLS
testforOLS = theft_test %>% select(-county, -state)
trainforOLS = theft_train %>% select(-county, -state) %>% mutate(fips = as.factor(fips))
lm_fit = lm(theftrate ~ ., data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
OLS_RMSE = sqrt(mean((OLS_predictions-testforOLS$theftrate)^2))
# OLS
testforOLS = theft_test %>% select(-county, -state)%>% mutate(fips = as.factor(fips))
trainforOLS = theft_train %>% select(-county, -state) %>% mutate(fips = as.factor(fips))
lm_fit = lm(theftrate ~ .-fips, data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
# OLS
testforOLS = theft_test %>% select(-county, -state)%>% mutate(fips = as.character(fips))
trainforOLS = theft_train %>% select(-county, -state) %>% mutate(fips = as.character(fips))
lm_fit = lm(theftrate ~ .-fips, data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
# OLS
testforOLS = theft_test %>% select(-county, -state)
trainforOLS = theft_train %>% select(-county, -state)
lm_fit = lm(theftrate ~ .-fips, data = testforOLS)
OLS_Predictions = predict(lm_fit, newdata = theft_test)
OLS_RMSE = sqrt(mean((OLS_predictions-testforOLS$theftrate)^2))
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
