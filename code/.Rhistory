write.csv(merge8, file = '../data/clean/merge8.csv', row.names = FALSE)
source("code/1-cleaning.R")
source("code/2-incar_rf.R")
source("code/3-cleaning2.R")
source("code/cleaning.R")
source("code/incar_rf.R")
source("code/cleaning2.R")
source("code/cleaning.R")
source("cleaning.R")
source("incar_rf.R")
source("cleaning2.R")
source("cleaning.rmd")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(tidycensus)
library(readxl)
library(usdata)
library(tm)
library(stringr)
var <- load_variables(2019, "acs1", cache = TRUE)
census_data <- get_acs(geography = "county", variables = c(med_age = "B01002_001",
permale = "B01001_002",
bachplus = "B16010_041",
totalpop = "B01003_001",
unemployed = "B27011_008",
employed =	"B27011_003",
foodstamp = "B09010_002",
ilefnhi= "B27011_007",
ilufnhi= "B27011_012",
nilfnhi = "B27011_017",
gini = "B19083_001",
med_income = "B19013_001",
med_2bed = "B25031_004",
single_mom = "B11012_010",
lessthan_hs = "B16010_002",
housing_units = "B25001_001"),
year = 2019)
census_step = census_data %>%
pivot_wider(id_cols = c(NAME), names_from = variable, values_from = estimate) %>%
separate(NAME, into = c("county", "state"), sep = ", ") %>% arrange(state, county)
census_wider = census_step %>%
mutate(permale = permale/totalpop,
bachplus = bachplus/totalpop, unemployed_rate = unemployed/(employed+unemployed), employed_rate = employed/(employed+unemployed),
foodstamp = foodstamp/totalpop, no_health_ins =
(ilefnhi+ilufnhi+nilfnhi)/totalpop, single_mom =
single_mom/totalpop, lessthan_hs = lessthan_hs/totalpop) %>%
select(-ilefnhi,-ilufnhi,-nilfnhi, -unemployed, -employed)
ACS_vars = drop_na(census_wider)
election = read_csv("../data/raw/president_county_candidate.csv",
col_types = cols(won = col_skip()))
election2 = election %>% arrange(state, county) %>%
group_by(state, county) %>%
mutate(pctvote = 100*total_votes/sum(total_votes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election_clean = election2 %>%
pivot_wider(id_cols = c(state, county),
names_from = candidate, values_from = pctvote)
ACS_election = election_clean %>% inner_join(ACS_vars, by = c("state", "county")) %>% select(-`Joe Biden`) %>% rename(pertrump = 'Donald Trump') %>% mutate(pertrump = pertrump/100)
keyfile = read_csv("../data/raw/ZIP-COUNTY-FIPS_2017-06.csv") %>%
mutate(state_full = abbr2state(STATE),) %>% rename(county = COUNTYNAME, state = state_full, fips = STCOUNTYFP) %>% select(-ZIP) %>% distinct()
ACS_election_key = ACS_election %>% inner_join(keyfile, by = c("state", "county")) %>%  mutate(fips = as.numeric(fips))
land = read_xlsx("../data/raw/land.xlsx") %>% rename(fips = STCOU, area = LND010190D) %>% mutate(fips = as.numeric(fips))
ACS_election_land = ACS_election_key %>% inner_join(land, by = "fips") %>% mutate(pop_density = totalpop/area, housing_density = housing_units/area) %>% select(-area, -housing_units)
poverty = read_xlsx("../data/raw/poverty.xlsx", skip = 1) %>% mutate(pct_all_in_pov = as.numeric(`Poverty Percent, All Ages`)/100, .keep = "unused")
poverty$fips = as.numeric(paste(poverty$`State FIPS Code`, poverty$`County FIPS Code`, sep = ""))
merge1 = ACS_election_land %>% inner_join(poverty, by = "fips") %>%
select(-STATE, -CLASSFP, -Areaname, -`State FIPS Code`, -`County FIPS Code`)
file = "../data/raw/scorecard.csv"
scorecard_raw = read_csv(file)
scorecard_raw = scorecard_raw %>% select("fips_state_code", "fips_county_code",
"calc_police_violence_score","calc_police_accountability_score",
"calc_approach_to_policing_score","calc_police_funding_score")
scorecard_raw = data.frame(sapply(scorecard_raw, function(x) as.numeric(gsub("%", "", x)))) %>%
rename(police_violence_score = calc_police_violence_score,
police_accountability_score=calc_police_accountability_score,
approach_to_policing_score = calc_approach_to_policing_score,
police_funding_score = calc_police_funding_score) %>%
mutate(fips_state_code=as.character(fips_state_code), fips_county_code = as.character(fips_county_code))
scorecard_raw$fips_county_code = str_pad(scorecard_raw$fips_county_code, 3, pad = "0")
scorecard_raw$fips = str_c(scorecard_raw$fips_state_code, scorecard_raw$fips_county_code)
scorecard_clean = scorecard_raw %>% select(-fips_state_code,-fips_county_code) %>%
mutate(fips = as.numeric(fips)) %>% group_by(fips) %>%
summarise(police_violence_score = mean(police_violence_score),
police_accountability_score = mean(police_accountability_score),
approach_to_policing_score = mean(approach_to_policing_score),
police_funding_score = mean(police_funding_score))
merge2 = merge1 %>% inner_join(scorecard_clean, by = "fips")
hha_raw = read_excel('../data/raw/HHS_OCDO_TDWG_COVID-19_Community_Vulnerability_Crosswalk.xlsx') %>% as_tibble()
mean_data = hha_raw %>% select(`County FIPS`,`HHA Score`) %>%
rename(fips = `County FIPS`, hha_score = `HHA Score`) %>%
mutate(fips=as.numeric(fips))%>%
group_by(fips) %>%
summarise(mean_hha_score = mean(hha_score))%>%
as_tibble()
merge3 = merge2 %>% inner_join(mean_data, by = "fips")
file = "../data/raw/Social_Vulnerability_Index_2018.csv"
vulner_raw = read_csv(file)
vulner_raw = vulner_raw %>% select("FIPS","RPL_THEMES")%>% filter(RPL_THEMES>=0)%>%
rename(fips = FIPS, svi_overall=RPL_THEMES)
vulner_raw$fips = as.numeric(vulner_raw$fips)
merge4 = merge3 %>% inner_join(vulner_raw, by = "fips")
file = "../data/raw/analytic_data2020_0.csv"
healthrank_raw = read_csv(file, skip=1)
healthrank_raw= healthrank_raw %>% select(fipscode,v142_rawvalue,
v024_rawvalue, v154_rawvalue, v136_rawvalue, v002_rawvalue) %>%
rename(res_seg_nonwhite_white = v142_rawvalue, pct_child_in_pov = v024_rawvalue, sev_hou_cost_burden = v154_rawvalue, sev_hou_prob = v136_rawvalue, poor_fair_health = v002_rawvalue , fips =fipscode)
healthrank_raw$fips = as.numeric(healthrank_raw$fips)
merge5 = merge4 %>% inner_join(healthrank_raw, by = "fips")
state_expenses = read_xlsx("../data/raw/expenditures.xlsx") %>% rename(state = State, spend_per_capita = `State and Local Direct General Expenditures, Per Capita`)
merge6 = merge5 %>% inner_join(state_expenses, by = "state")
unemp_bens = read_xlsx("../data/raw/unemployment bens.xlsx")
stopwords3 = c("Individual", "w/dependents", "up", "to")
unemp_bens$amount = removeWords(unemp_bens$amount, stopwords3)
unemp_bens = unemp_bens %>% separate(amount, into = c("individual", "w_dependents"), sep = "  ") %>% mutate(individual = extract_numeric(individual), w_dependents = extract_numeric(w_dependents))
unemp_bens$w_dependents = ifelse(is.na(unemp_bens$w_dependents), unemp_bens$individual, unemp_bens$w_dependents)
unemp_bens = unemp_bens %>% mutate(average_bens = (as.numeric(individual)+as.numeric(w_dependents))/2) %>% mutate(unemp_bens_possible = average_bens*weeks) %>% select(state, unemp_bens_possible)
merge7 = merge6 %>% inner_join(unemp_bens, by = "state")
census_data_zip <- get_acs(geography = "zcta", variables = c(totalpop = "B01003_001"),
year = 2018)
census_step_zip = census_data_zip %>%
pivot_wider(id_cols = c(NAME), names_from = variable, values_from = estimate) %>%
separate(NAME, into = c("zcta", "zip"), sep = " ") %>% select(-zcta) %>% mutate(zip = as.numeric(zip))
file = "../data/raw/irstiny.csv"
irs_raw = read_csv(file)
irs_raw = irs_raw%>%select(zipcode, N07240)%>% mutate(zip = as.numeric(zipcode),saverscredit = N07240)%>%select(-zipcode,-N07240) %>% group_by(zip) %>% summarise(saverscredit = sum(saverscredit))%>%ungroup()
irs_clean = irs_raw%>% inner_join(census_step_zip, by="zip") %>% mutate(saversperpop=saverscredit/totalpop)
file = "../data/raw/ZIP-COUNTY-FIPS_2017-06.csv"
key_zip_county = read_csv(file)
key_zip_county = key_zip_county %>% rename(zip=ZIP, county=COUNTYNAME, fips=STCOUNTYFP)%>% mutate(zip=as.numeric(zip)) %>% select(zip, county,fips)
irs_joined = key_zip_county%>%inner_join(irs_clean, by="zip")
irs_final = irs_joined%>%group_by(fips)%>% summarise(saversperpop = mean(saversperpop)) %>% ungroup() %>% mutate(fips=as.numeric(fips))
merge8=merge7 %>%inner_join(irs_final,by="fips") %>% drop_na()
write.csv(merge8, file = '../data/clean/merge8.csv', row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(usdata)
library(tm)
library(stringr)
library(randomForest)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
merge8 = read_csv("../data/clean/merge8.csv")
url = "https://raw.githubusercontent.com/themarshallproject/incarceration-census/main/census_incarceration.csv"
incar_raw = read_csv(url) %>% select(FIPS, state, county, total_population_20, incarcerated_20)%>%
mutate(incar_rate = incarcerated_20/total_population_20) %>%
select(incar_rate, FIPS) %>% rename(fips = FIPS) %>% ungroup()
incarvars = merge8 %>% inner_join(incar_raw, by = "fips") %>% select(-totalpop) %>% drop_na() %>% as.data.frame()
incar_0 = incarvars %>% filter(incar_rate == 0)
incar_complete = incarvars %>% filter(!(incar_rate == 0)) %>% drop_na()
incar_0rf = incar_0 %>% select(-fips, -county, -state)
incar_completerf = incar_complete %>% as.data.frame() %>% select(-fips, -county, -state)
train_samples = sample(1:nrow(incar_completerf), round(0.8*nrow(incar_completerf)))
incar_train = incar_completerf %>% filter(row_number() %in% train_samples)
incar_test = incar_completerf %>% filter(!(row_number() %in% train_samples))
set.seed(471)
rf_fit = randomForest(incar_rate ~ ., data = incar_train)
rf_predictions = predict(rf_fit, newdata = incar_test)
mean((rf_predictions - incar_test$incar_rate)^2)
set.seed(471)
rf_fit2 = randomForest(incar_rate ~ ., data = incar_completerf)
rf_predictions2 = predict(rf_fit2, newdata = incar_0rf)
incar_predicted = incar_0
incar_predicted$incar_rate = rf_predictions2
incar_final = rbind(incar_predicted, incar_complete) %>% drop_na() %>% select(incar_rate, fips)
merge9 = merge8 %>% inner_join(incar_final, by = "fips")
write.csv(merge9, file = '../data/clean/merge9incar.csv', row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
hope = read.csv("https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv", sep = "|") %>% rename(State = State.full)
hope = hope %>% select(-City.alias)
countycrime = read_xlsx("../data/raw/countycrime.xlsx") %>% select(State, County, Total_Theft)
citycrime = read_xlsx("../data/raw/citycrime.xlsx")
citycrime$State = removeNumbers(citycrime$State)
citycrime$City = removeNumbers(citycrime$City)
countycrime$State = removeNumbers(countycrime$State)
countycrime$County = removeNumbers(countycrime$County)
countycrime$county_words = sapply(gregexpr("\\S+", countycrime$County), length)
stopwords = c(" County Police Department", " County Unified Police Department", " Public Safety")
countycrime$County = removeWords(countycrime$County, stopwords)
countycrime = countycrime %>% group_by(County, State) %>% summarise(Total_Theft = sum(Total_Theft)) %>% ungroup()
citycrimecounty = hope %>% inner_join(citycrime, by = c("State", "City")) %>% distinct()
citycrimecounty$County = tolower(citycrimecounty$County)
citycrimecounty$County = str_to_title(citycrimecounty$County)
citiestocounties = citycrimecounty %>% group_by(County, State) %>% summarise(Total_Thefts = sum(Total_Thefts))
citiestocounties$County_State = paste(citiestocounties$County, citiestocounties$State)
countycrime$County_State = paste(countycrime$County, countycrime$State)
missingcounties = citiestocounties %>% filter(!(County_State %in% countycrime$County_State))  %>% rename(Total_Theft = Total_Thefts)
response = rbind(missingcounties, countycrime) %>% drop_na() %>% rename(county = County, state = State)
keyfile2 = read_csv("../data/raw/ZIP-COUNTY-FIPS_2017-06.csv") %>%
mutate(state_full = abbr2state(STATE),) %>% rename(county = COUNTYNAME, state = state_full, fips = STCOUNTYFP) %>% select(-ZIP) %>% distinct()
stopwords3 = c(" County")
keyfile2$county = removeWords(keyfile2$county, stopwords3)
keyfile2$County_State = paste(keyfile2$county, keyfile2$state)
responsekey = keyfile2 %>%  inner_join(response, by = "County_State") %>% select(fips, Total_Theft) %>% mutate(fips = as.numeric(fips))
merge9incar = read_csv("../data/clean/merge9incar.csv")
merge_with_response = merge9incar %>% inner_join(responsekey, by = "fips") %>% mutate(theftrate = Total_Theft/totalpop, .keep = "unused")
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
hope = read.csv("https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv", sep = "|") %>% rename(State = State.full)
hope = hope %>% select(-City.alias)
countycrime = read_xlsx("../data/raw/countycrime.xlsx") %>% select(State, County, Total_Theft)
citycrime = read_xlsx("../data/raw/citycrime.xlsx")
citycrime$State = removeNumbers(citycrime$State)
citycrime$City = removeNumbers(citycrime$City)
countycrime$State = removeNumbers(countycrime$State)
countycrime$County = removeNumbers(countycrime$County)
countycrime$county_words = sapply(gregexpr("\\S+", countycrime$County), length)
stopwords = c(" County Police Department", " County Unified Police Department", " Public Safety")
countycrime$County = removeWords(countycrime$County, stopwords)
countycrime = countycrime %>% group_by(County, State) %>% summarise(Total_Theft = sum(Total_Theft)) %>% ungroup()
citycrimecounty = hope %>% inner_join(citycrime, by = c("State", "City")) %>% distinct()
citycrimecounty$County = tolower(citycrimecounty$County)
citycrimecounty$County = str_to_title(citycrimecounty$County)
citiestocounties = citycrimecounty %>% group_by(County, State) %>% summarise(Total_Thefts = sum(Total_Thefts))
citiestocounties$County_State = paste(citiestocounties$County, citiestocounties$State)
countycrime$County_State = paste(countycrime$County, countycrime$State)
missingcounties = citiestocounties %>% filter(!(County_State %in% countycrime$County_State))  %>% rename(Total_Theft = Total_Thefts)
response = rbind(missingcounties, countycrime) %>% drop_na() %>% rename(county = County, state = State)
keyfile2 = read_csv("../data/raw/ZIP-COUNTY-FIPS_2017-06.csv") %>%
mutate(state_full = abbr2state(STATE),) %>% rename(county = COUNTYNAME, state = state_full, fips = STCOUNTYFP) %>% select(-ZIP) %>% distinct()
stopwords3 = c(" County")
keyfile2$county = removeWords(keyfile2$county, stopwords3)
keyfile2$County_State = paste(keyfile2$county, keyfile2$state)
responsekey = keyfile2 %>%  inner_join(response, by = "County_State") %>% select(fips, Total_Theft) %>% mutate(fips = as.numeric(fips))
merge9incar = read_csv("../data/clean/merge9incar.csv")
merge_with_response = merge9incar %>% inner_join(responsekey, by = "fips") %>% mutate(theftrate = Total_Theft/totalpop, .keep = "unused")
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
merge_with_response = merge9incar %>% inner_join(responsekey, by = "fips") %>% mutate(theftrate = Total_Theft/totalpop, .keep = "unused") %>% drop_na()
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
View(incar_train)
merge_with_response = merge9incar %>% inner_join(responsekey, by = "fips") %>% mutate(theftrate = Total_Theft/totalpop, .keep = "unused") %>% drop_na()
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(tidycensus)
library(readxl)
library(usdata)
library(tm)
library(stringr)
dataclean = read.csv("../data/clean/dataclean.csv")
View(dataclean)
map_data("county") %>%
as_tibble() %>%
left_join(dataclean %>%
rename(region = state,
subregion = county,
`Theft Rate` = theftrate) %>%
mutate(region = str_to_lower(region),
subregion = str_to_lower(subregion)),
by = c("region", "subregion")) %>%
ggplot() +
geom_polygon(data=map_data("state"),
aes(x=long, y=lat, group=group),
color="black", fill=NA,  size = 1, alpha = .3) +
geom_polygon(aes(x=long, y=lat, group=group, fill = `Theft Rate`),
color="darkblue", size = .1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_void()
options(scipen = 0, digits = 3)  # controls number of significant digits printed
library(kableExtra)                     # for printing tables
library(cowplot)                        # for side by side plots
library(glmnetUtils)                    # to run ridge and lasso
library(lubridate)                      # for dealing with dates
library(maps)                           # for creating maps
source("../../functions/plot_glmnet.R") # for lasso/ridge trace plots
library(tidyverse)                      # for everything else
# read case data from URL
url = "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
case_data_raw = read_csv(url)
# read county health data from file
county_health_data = read_tsv("../../data/county_health_data.tsv")
# print the two tibbles
case_data_raw
county_health_data
# wrangle case data
case_data = case_data_raw %>%
na.omit() %>%                               # remove NA values
filter(year(date) == 2020) %>%              # keep data from 2020
group_by(fips, county, state) %>%           # group by county
summarise(total_cases = sum(cases),         # total cases per county
total_deaths = sum(deaths)) %>%   # total deaths per county
ungroup() %>%
mutate(case_fatality_rate =                 # case_fatality_rate =
total_deaths/total_cases*100) %>%  #  total_deaths/total_cases
select(-total_cases, -total_deaths)         # remove intermediate variables
# print case data
case_data
# join county health data with case data
covid_data = inner_join(county_health_data, case_data, by = "fips")
covid_data
View(covid_data)
merge_with_response = merge9incar %>% inner_join(responsekey, by = "fips") %>% mutate(theftrate = Total_Theft/totalpop, .keep = "unused") %>% drop_na()
merge_with_response$county = removeWords(merge_with_response$county, stopwords3)
write.csv(merge_with_response, file = '../data/clean/dataclean.csv', row.names = FALSE)
dataclean = read.csv("../data/clean/dataclean.csv")
map_data("county") %>%
as_tibble() %>%
left_join(dataclean %>%
rename(region = state,
subregion = county,
`Theft Rate` = theftrate) %>%
mutate(region = str_to_lower(region),
subregion = str_to_lower(subregion)),
by = c("region", "subregion")) %>%
ggplot() +
geom_polygon(data=map_data("state"),
aes(x=long, y=lat, group=group),
color="black", fill=NA,  size = 1, alpha = .3) +
geom_polygon(aes(x=long, y=lat, group=group, fill = `Theft Rate`),
color="darkblue", size = .1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_void()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
theftdata = read.csv("../data/clean/dataclean.csv")
theft_samples = sample(1:nrow(theft), round(0.8*nrow(theft)))
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata)))
theft_train = theft %>% filter(row_number() %in% train_samples)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata)))
theft_train = theftdata %>% filter(row_number() %in% train_samples)
theft_test = theftdata %>% filter(!(row_number() %in% train_samples))
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theft ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
library(gbm)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theft ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata))) %>% select(-county, -state, -fips)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata))) %>% dplyr::select(-county, -state, -fips)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata))) %>% tibble() %>%  dplyr::select(-county, -state, -fips)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata))) %>% as.data.frame() %>% select(-county, -state, -fips)
theftdata = read.csv("../data/clean/dataclean.csv") %>% as.data.frame() %>% select(-county, -state, -fips)
theft_samples = sample(1:nrow(theftdata), round(0.8*nrow(theftdata)))
theft_train = theftdata %>% filter(row_number() %in% train_samples)
theft_test = theftdata %>% filter(!(row_number() %in% train_samples))
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 3
gbm_3 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(1) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 3
gbm_3 = gbm(theftrate ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
View(dataclean)
ntrees = 1000
cv_errors = bind_rows(
tibble(ntree = 1:ntrees, cv_err = gbm_1$cv.error, Depth = 1),
tibble(ntree = 1:ntrees, cv_err = gbm_2$cv.error, Depth = 2),
tibble(ntree = 1:ntrees, cv_err = gbm_3$cv.error, Depth = 3)
) %>% mutate(Depth = factor(Depth))
# plot CV errors
mins = cv_errors %>% group_by(Depth) %>% summarise(min_err = min(cv_err))
gbm.perf(gbm_3, plot.it = FALSE)
cv_errors %>%
ggplot(aes(x = ntree, y = cv_err, colour = Depth)) +
geom_line() + theme_bw() +
geom_hline(aes(yintercept = min_err, color = Depth),
data = mins, linetype = "dashed") +
labs(y = "CV Error", x = "Trees") + scale_y_log10()
gbm_fit_optimal = gbm_3
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10) %>% kable(format = "latex", row.names = NA,
booktabs = TRUE,
digits = 4,
col.names = c("Feature", "Relative Influence"),
caption = "Boosting relative influence table.") %>%
kable_styling(position = "center")
gbm_fit_optimal = gbm_3
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_3, i.var = "char_freq_exclamation_mark",
n.trees = unemp_bens_possible	, type = "response")
gbm_fit_optimal = gbm_1
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
gbm_fit_optimal = gbm_1
optimal_num_trees = gbm.perf(gbm_1, plot.it = FALSE)
summary(gbm_1, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_1, i.var = "char_freq_exclamation_mark",
n.trees = unemp_bens_possible	, type = "response")
gbm_fit_optimal = gbm_1
optimal_num_trees = gbm.perf(gbm_1, plot.it = FALSE)
summary(gbm_1, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_3, i.var = "unemp_bens_possible",
n.trees = optimal_num_trees, type = "response")
plot(gbm_3, i.var = "pertrump",
n.trees = optimal_num_trees, type = "response")
plot(gbm_3, i.var = "unemp_bens_possible",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "pertrump",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "housing_density", n.trees =
optimal_num_trees)
