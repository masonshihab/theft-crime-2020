oob_errors = numeric(length(mvalues))
ntree = 500
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit = randomForest(theftrate ~. -fips -state - county, mtry = m, data = theft_train)
oob_errors[idx] = rf_fit$mse[ntree]
}
tibble(m = mvalues, oob_err = oob_errors) %>%
ggplot(aes(x = m, y = oob_err)) +
geom_line() + geom_point() +
scale_x_continuous(breaks = mvalues) +
theme_bw()
set.seed(471) # set seed for reproducibility
rf_13 = randomForest(theftrate ~ .-fips -state -county, mtry = 13, data = theft_train)
rf_13$importance
varImpPlot(rf_13,n.var = 10)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 3
gbm_3 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
ntrees = 1000
cv_errors = bind_rows(
tibble(ntree = 1:ntrees, cv_err = gbm_1$cv.error, Depth = 1),
tibble(ntree = 1:ntrees, cv_err = gbm_2$cv.error, Depth = 2),
tibble(ntree = 1:ntrees, cv_err = gbm_3$cv.error, Depth = 3)
) %>% mutate(Depth = factor(Depth))
# plot CV errors
mins = cv_errors %>% group_by(Depth) %>% summarise(min_err = min(cv_err))
gbm.perf(gbm_3, plot.it = FALSE)
cv_errors %>%
ggplot(aes(x = ntree, y = cv_err, colour = Depth)) +
geom_line() + theme_bw() +
geom_hline(aes(yintercept = min_err, color = Depth),
data = mins, linetype = "dashed") +
labs(y = "CV Error", x = "Trees") + scale_y_log10()
gbm_fit_optimal = gbm_3
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_3, i.var = "housing_density",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "poor_fair_health",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "pertrump", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "PctEmpFIRE", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "pop_density", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "unemp_bens_possible", n.trees =
optimal_num_trees)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
Response_Mean
mean(theft_test$theftrate)
View(merge_with_response)
View(merge10)
View(merge_with_response)
# run all steps of the analysis pipeline
setwd("C:/Users/Mason Shihab/Documents/MBDS/471/final-project-template/code")
#setwd("/Users/diyangchu/Documents/2-grad@Penn/STAT471/theft-crime-2020/code")
source("1-cleaning.R")
source("2.1-imputation.R")
source("2.2-cleaning2.R")
source("2.3-train-test-split.R")
#source("2-exploration.R")
#source("4-regression-modeling.R")
#source("5-tree-modeling.R")
#source("6-model-evaluation.R")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
library(gbm)
library(glmnetUtils) # boosting
library(randomForest)
# install.packages("scales")              # dependency of plot_glmnet
source("functions/plot_glmnet.R")
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
set.seed(471) # set seed for reproducibility
ridge_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = 0,                 # alpha = 0 for ridge
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(readxl)
library(usdata)
library(tm)
library(stringr)
library(gbm)
library(glmnetUtils) # boosting
library(randomForest)
# install.packages("scales")              # dependency of plot_glmnet
source("functions/plot_glmnet.R")
theft_train = read_csv("../data/clean/theft_train.csv")
theft_test = read_csv("../data/clean/theft_test.csv")
set.seed(471) # set seed for reproducibility
ridge_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = 0,                 # alpha = 0 for ridge
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
plot(ridge_fit)
plot_glmnet(ridge_fit, theft_train, features_to_plot = 8)
set.seed(471) # set seed before cross-validation for reproducibility
lasso_fit = cv.glmnet(theftrate ~. -state -county -fips , alpha = 1, nfolds = 10, data = theft_train)
plot(lasso_fit)
lambda_lasso = lasso_fit$lambda.1se
sprintf("The value of lambda based on the one-standard-error rule: %f",
lambda_lasso)
num_features = lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se]
sprintf("The number of features (excluding intercept) selected (1se): %i",
num_features)
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(coefficient))
plot_glmnet(lasso_fit, theft_train)
elnet_fit = cva.glmnet(theftrate ~ .-fips -county -state, # formula notation, as usual
nfolds = 10,               # number of folds
data = theft_train)   # data to run on
elnet_fit$alpha
plot_cva_glmnet(elnet_fit)
elnet_fit_best = extract_best_elnet(elnet_fit)
elnet_fit_best$alpha
plot(elnet_fit_best)
plot_glmnet(elnet_fit_best, theft_train)
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
extract_std_coefs(elnet_fit_best, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(abs(coefficient)))
set.seed(471) # set seed for reproducibility
final_elnet_fit = cv.glmnet(theftrate ~ .-fips -state -county,  # formula notation, as usual
alpha = elnet_fit_best$alpha,
nfolds = 10,               # number of folds
data = theft_train)   # data to run ridge on
set.seed(471) # set seed for reproducibility
mvalues = seq(4,16, by = 1)
oob_errors = numeric(length(mvalues))
ntree = 500
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit = randomForest(theftrate ~. -fips -state - county, mtry = m, data = theft_train)
oob_errors[idx] = rf_fit$mse[ntree]
}
tibble(m = mvalues, oob_err = oob_errors) %>%
ggplot(aes(x = m, y = oob_err)) +
geom_line() + geom_point() +
scale_x_continuous(breaks = mvalues) +
theme_bw()
set.seed(471) # set seed for reproducibility
rf_13 = randomForest(theftrate ~ .-fips -state -county, mtry = 13, data = theft_train)
rf_13$importance
varImpPlot(rf_13,n.var = 10)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 1
gbm_1 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 2
gbm_2 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
set.seed(471) # for reproducibility (DO NOT CHANGE)
# TODO: Fit random forest with interaction depth 3
gbm_3 = gbm(theftrate ~ . -fips -state -county,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = theft_train)
ntrees = 1000
cv_errors = bind_rows(
tibble(ntree = 1:ntrees, cv_err = gbm_1$cv.error, Depth = 1),
tibble(ntree = 1:ntrees, cv_err = gbm_2$cv.error, Depth = 2),
tibble(ntree = 1:ntrees, cv_err = gbm_3$cv.error, Depth = 3)
) %>% mutate(Depth = factor(Depth))
# plot CV errors
mins = cv_errors %>% group_by(Depth) %>% summarise(min_err = min(cv_err))
gbm.perf(gbm_3, plot.it = FALSE)
cv_errors %>%
ggplot(aes(x = ntree, y = cv_err, colour = Depth)) +
geom_line() + theme_bw() +
geom_hline(aes(yintercept = min_err, color = Depth),
data = mins, linetype = "dashed") +
labs(y = "CV Error", x = "Trees") + scale_y_log10()
gbm_fit_optimal = gbm_3
optimal_num_trees = gbm.perf(gbm_3, plot.it = FALSE)
summary(gbm_3, n.trees = optimal_num_trees, plotit = FALSE) %>% tibble() %>%
head(10)
plot(gbm_3, i.var = "housing_density",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "poor_fair_health",
n.trees = optimal_num_trees)
plot(gbm_3, i.var = "pertrump", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "PctEmpFIRE", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "pop_density", n.trees =
optimal_num_trees)
plot(gbm_3, i.var = "unemp_bens_possible", n.trees =
optimal_num_trees)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_13, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
mean(theft_test$theftrate)
set.seed(471) # set seed for reproducibility
rf_12 = randomForest(theftrate ~ .-fips -state -county, mtry = 12, data = theft_train)
rf_12$importance
varImpPlot(rf_12,n.var = 10)
# ridge prediction error
ridge_predictions = predict(ridge_fit,
newdata = theft_test,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(mean((ridge_predictions-theft_test$theftrate)^2))
# lasso prediction error
lasso_predictions = predict(lasso_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
lasso_RMSE = sqrt(mean((lasso_predictions-theft_test$theftrate)^2))
# elnet prediction error
elnet_predictions = predict(final_elnet_fit,
newdata = theft_test,
s = "lambda.1se") %>%
as.numeric()
elnet_RMSE = sqrt(mean((elnet_predictions-theft_test$theftrate)^2))
# intercept-only prediction error
training_mean_response = mean(theft_test$theftrate)
constant_RMSE = sqrt(mean((training_mean_response-theft_test$theftrate)^2))
#RF
rf_predictions = predict(rf_12, newdata = theft_test)
rf_RMSE = sqrt(mean((rf_predictions-theft_test$theftrate)^2))
#Boosting
gbm_predictions = predict(gbm_3, n.trees = optimal_num_trees,
newdata = theft_test)
gbm_RMSE = sqrt(mean((gbm_predictions-theft_test$theftrate)^2))
# print nice table
tibble(Ridge = ridge_RMSE, Lasso = lasso_RMSE, `Intercept-only` = constant_RMSE,
Elastic_Net = elnet_RMSE, Random_Forest = rf_RMSE, Boosting = gbm_RMSE) %>% pivot_longer(everything(), names_to = "Model", values_to = "Test RMSE")
extract_std_coefs(lasso_fit, theft_train) %>%
filter(coefficient != 0) %>% arrange(desc(abs(coefficient)))
plot_glmnet(elnet_fit_best, theft_train)
plot_glmnet(elnet_fit_best, theft_train, features_to_plot = 10)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv",
col_types = cols(won = col_skip()))
View(election)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% arrange(state, county) %>% filter(year == 2020)
group_by(state, county) %>%
mutate(pctvote = 100*total_votes/sum(total_votes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election2 = election %>% arrange("state", "county") %>% filter(year == 2020)
group_by(state, county) %>%
mutate(pctvote = 100*total_votes/sum(total_votes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election2 = election %>% filter(year == 2020)
group_by(state, county) %>%
mutate(pctvote = 100*total_votes/sum(total_votes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election2 = election %>% filter(year == 2020) %>%
mutate(pctvote = 100*total_votes/sum(total_votes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election2 = election %>% filter(year == 2020) %>%
mutate(pctvote = 100*total_votes/sum(totalvotes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
election2 = election %>% filter(year == 2020) %>%
mutate(pctvote = 100*totalvotes/sum(totalvotes)) %>%
filter(candidate %in% c("Joe Biden", "Donald Trump"))
View(election2)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP") %>% select(fips, pctvote)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP") %>%
rename(pertrump = "DONALD TRUMP") %>% select(county_fips, pertrump)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP") %>%
rename(pertrump = pctvote) %>% select(county_fips, pertrump)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP") %>%
mutate(pertrump = candidatevotes/totalvotes) %>% select(county_fips, pertrump)
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP") %>%
mutate(pertrump = candidatevotes/totalvotes)
election2 = election %>% filter(year == 2020, candidate == "DONALD TRUMP")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv") %>% filter(year == 2020, candidate == "DONALD TRUMP")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv") %>% filter(candidate == "DONALD TRUMP")
election
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv") %>% filter(candidate == "DONALD TRUMP") %>% filter(year == 2020)
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv") %>% filter(candidate == "DONALD TRUMP") %>%
filter(year == "2020")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv") %>% filter(candidate == "DONALD TRUMP")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP")
mutate(pertrump = candidatevotes/totalvotes) %>% select(county_fips, pertrump)
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP")
View(election2)
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% mutate(pertrump = candidatevotes/totalvotes)
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(fips_codes) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes))
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes))
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>% mutate(pertrump = candidatevotes/totalvotes)
View(election2)
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>%
mutate(pertrump = candidatevotes/totalvotes, .keep = "unused")
ACS_election = election_clean %>% inner_join(ACS_vars, by = fips)
election2
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>%
mutate(pertrump = candidatevotes/totalvotes, .keep = "unused") %>% rename(fips = county_fips)
ACS_election = election_clean %>% inner_join(ACS_vars, by = fips)
## ----setup, include=FALSE---------------------------------------------------------------------------------------------------------------------
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(readr)
library(tidycensus)
library(readxl)
library(usdata)
library(tm)
library(stringr)
## ---------------------------------------------------------------------------------------------------------------------------------------------
var <- load_variables(2019, "acs1", cache = TRUE)
## ---------------------------------------------------------------------------------------------------------------------------------------------
census_data <- get_acs(geography = "county", variables = c(med_age = "B01002_001",
permale = "B01001_002",
bachplus = "B16010_041",
totalpop = "B01003_001",
unemployed = "B27011_008",
employed =	"B27011_003",
foodstamp = "B09010_002",
ilefnhi= "B27011_007",
ilufnhi= "B27011_012",
nilfnhi = "B27011_017",
gini = "B19083_001",
med_income = "B19013_001",
med_2bed = "B25031_004",
single_mom = "B11012_010",
lessthan_hs = "B16010_002",
housing_units = "B25001_001",
households = "B11001_002",
inschool = "B14001_002",
ingradprofesh = "B14001_009",
inundergrad = "B14001_008",
Marriedcouplefamily = "B11001_003",
withkids = "B23009_002",
singledad = "B19131_039",
divorced = "B07008_004",
nevermarried = "B06008_002",
foreignborn = "B99051_005",
fromdifstate = "B07001_065",
fromabroad = "B07001_081",
widowed = "B06008_006",
dis5to17male = "B18101_007",
dis5to17female = "B18101_026",
dis18to34male = "B18101_010",
dis18to34female = "B18101_029",
dis35to64male = "B18101_013",
dis35to64female = "B18101_032",
year = 2019))
## ---------------------------------------------------------------------------------------------------------------------------------------------
census_step = census_data %>%
pivot_wider(id_cols = c(NAME), names_from = variable, values_from = estimate) %>%
separate(NAME, into = c("county", "state"), sep = ", ") %>% arrange(state, county)
census_wider = census_step %>%
mutate(permale = permale/totalpop,
bachplus = bachplus/totalpop, unemployed_rate = unemployed/(employed+unemployed), employed_rate = employed/(employed+unemployed),
foodstamp = foodstamp/totalpop, no_health_ins =
(ilefnhi+ilufnhi+nilfnhi)/totalpop, single_mom =
single_mom/households, lessthan_hs = lessthan_hs/totalpop, inschool = inschool/totalpop, ingradprofesh = ingradprofesh/totalpop, inundergrad = inundergrad/totalpop, Marriedcouplefamily = Marriedcouplefamily/households, withkids = withkids/households, singledad = singledad/households, divorced = divorced/totalpop, widowed = widowed/totalpop, nevermarried = nevermarried/totalpop, foreignborn = foreignborn/totalpop, fromdifstate = fromdifstate/totalpop, fromabroad = fromabroad/totalpop) %>% mutate(
dis5to17 = (dis5to17male + dis5to17female)/totalpop,
dis18to34 = (dis18to34male + dis18to34female)/totalpop,
dis35to64 = (dis35to64male + dis35to64female)/totalpop,
) %>%
select(-ilefnhi,-ilufnhi,-nilfnhi, -unemployed, -employed, -dis5to17male, -dis5to17female, -dis18to34male, -dis18to34female, -dis35to64male, -dis35to64female)
ACS_vars = drop_na(census_wider)
## ---------------------------------------------------------------------------------------------------------------------------------------------
keyfile = read_csv("../data/raw/ZIP-COUNTY-FIPS_2017-06.csv") %>%
mutate(state_full = abbr2state(STATE),) %>% rename(county = COUNTYNAME, state = state_full, fips = STCOUNTYFP) %>% select(-ZIP) %>% distinct()
## ---------------------------------------------------------------------------------------------------------------------------------------------
ACS_key = ACS_vars %>% inner_join(keyfile, by = c("state", "county")) %>%  mutate(fips = as.numeric(fips))
## ---------------------------------------------------------------------------------------------------------------------------------------------
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>%
mutate(pertrump = candidatevotes/totalvotes, .keep = "unused") %>% rename(fips = county_fips)
ACS_election_key = election2 %>% inner_join(ACS_vars, by = fips)
ACS_election_key = election2 %>% inner_join(ACS_key, by = fips)
## ---------------------------------------------------------------------------------------------------------------------------------------------
ACS_key = ACS_vars %>% inner_join(keyfile, by = c("state", "county")) %>%  mutate(fips = as.numeric(fips))
ACS_election_key = election2 %>% inner_join(ACS_key, by = fips)
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>%
mutate(pertrump = candidatevotes/totalvotes, .keep = "unused") %>% rename(fips = county_fips)
ACS_election_key = election2 %>% inner_join(ACS_key, by = fips)
View(election2)
View(ACS_key)
## ---------------------------------------------------------------------------------------------------------------------------------------------
ACS_key = ACS_vars %>% inner_join(keyfile, by = c("state", "county")) %>%  mutate(fips = as.numeric(fips))
## ---------------------------------------------------------------------------------------------------------------------------------------------
election = read_csv("../data/raw/County Presidential Election Returns 2000-2020.csv")
election2 = election %>% filter(year == 2020, candidate == "DONALD J TRUMP") %>% group_by(county_fips) %>%
summarise(candidatevotes = sum(candidatevotes), totalvotes = sum(totalvotes)) %>%
mutate(pertrump = candidatevotes/totalvotes, .keep = "unused") %>% rename(fips = county_fips)
ACS_election_key = election2 %>% inner_join(ACS_key, by = fips)
ACS_election_key = election2 %>% inner_join(ACS_key, by = "fips")
View(ACS_election_key)
